{
 "cells": [
  {
   "cell_type": "code",
   "id": "72a5867161b718bf",
   "metadata": {},
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b19b2bc1be1df99a",
   "metadata": {},
   "source": [
    "import pm4py\n",
    "import scipy\n",
    "import stormpy\n",
    "from copy import deepcopy\n",
    "import numpy as np"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "13bcc2fe638199ac",
   "metadata": {},
   "source": [
    "from simulation.markov_models import log_parser\n",
    "from simulation.markov_chain import apply as mc_apply\n",
    "from simulation.markov_chain_vis import view_markov_chain, view_resource_markov_chain, view_non_resource_markov_chain, view_resource_dfg, view_non_resource_dfg\n",
    "import simulation.util as sim_util\n",
    "\n",
    "np.random.seed(42)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Synthetic event log generation",
   "id": "808973a662193b3c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ctmc analysis hyper-parameters\n",
    "epsilon = 1\n",
    "\n",
    "# Simulation parameters\n",
    "num_traces = 1000\n",
    "make_repetitions = False\n",
    "\n",
    "add_randomness = False"
   ],
   "id": "8a4694dd6b47a86f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "time_sampling_strategies = {0:'exponential',1:'uniform',2:'normal',3:'exp-uni',4:'uni-exp',5:'exp-norm',6:'norm-exp'}\n",
    "chosen_time_strategy = time_sampling_strategies[0]"
   ],
   "id": "ca502123455f5ca9",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "511f48658bda4621",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import expon, sem, t, kstest\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Simulation parameters\n",
    "event_labels = [\"Acc\", \"Que\", \"Com\"]\n",
    "rate_for_test = 0.25\n",
    "\n",
    "r1_flag = True\n",
    "go_middle_flag = True\n",
    "\n",
    "resources = [\"Bob\",\"Alice\", \"Carmen\", \"Denis\", \"Ed\"]\n",
    "# Generate synthetic event log\n",
    "rows = []\n",
    "for case_id in range(1, num_traces + 1):\n",
    "    current_time = datetime.now()\n",
    "    case_id_str = str(case_id)\n",
    "\n",
    "    rows.append({\n",
    "        \"case:concept:name\": case_id_str,\n",
    "        \"concept:name\": \"Acc\",\n",
    "        \"org:role\": \"Manager\",\n",
    "        \"org:resource\": \"Alice\",\n",
    "        \"time:timestamp\": current_time\n",
    "    })\n",
    "    go_middle = bool(random.getrandbits(1)) if add_randomness else go_middle_flag\n",
    "    go_middle_flag = not go_middle_flag\n",
    "    number_of_times = int(random.uniform(1, 5)) if add_randomness else 3\n",
    "    if not make_repetitions:\n",
    "        number_of_times = 1\n",
    "    if go_middle:\n",
    "        for repetition in range(number_of_times):\n",
    "            match chosen_time_strategy:\n",
    "                case 'exponential':\n",
    "                    current_time += timedelta(hours=np.random.exponential(1 / rate_for_test))\n",
    "                case 'uniform':\n",
    "                    current_time += timedelta(hours=random.uniform(2, 6))\n",
    "                case 'normal':\n",
    "                    current_time += timedelta(hours=np.random.normal(loc=4, scale=1))\n",
    "                case 'exp-uni':\n",
    "                    current_time += timedelta(hours=np.random.exponential(1 / rate_for_test))\n",
    "                case 'uni-exp':\n",
    "                    current_time += timedelta(hours=random.uniform(2, 6))\n",
    "                case 'exp-norm':\n",
    "                    current_time += timedelta(hours=np.random.exponential(1 / rate_for_test))\n",
    "                case 'norm-exp':\n",
    "                    current_time += timedelta(hours=np.random.normal(loc=4, scale=1))\n",
    "            choose_r1 = bool(random.getrandbits(1)) if add_randomness else r1_flag\n",
    "            r1_flag = not r1_flag\n",
    "            rows.append({\n",
    "                \"case:concept:name\": case_id_str,\n",
    "                \"concept:name\": \"Que\",\n",
    "                \"org:role\": \"Manager\" if choose_r1 else \"Employee\",\n",
    "                \"org:resource\": f\"{resources[random.randint(1, 2)-1]}\" if choose_r1 else  f\"{resources[random.randint(1, 5)-1]}\",\n",
    "                \"time:timestamp\": current_time\n",
    "            })\n",
    "\n",
    "    match chosen_time_strategy:\n",
    "        case 'exponential':\n",
    "            current_time += timedelta(hours=np.random.exponential(1 / rate_for_test))\n",
    "        case 'uniform':\n",
    "            current_time += timedelta(hours=random.uniform(2, 6))\n",
    "        case 'normal':\n",
    "            current_time += timedelta(hours=np.random.normal(loc=4, scale=1))\n",
    "        case 'exp-uni':\n",
    "            current_time += timedelta(hours=random.uniform(2, 6))\n",
    "        case 'uni-exp':\n",
    "            current_time += timedelta(hours=np.random.exponential(1 / rate_for_test))\n",
    "        case 'exp-norm':\n",
    "            current_time += timedelta(hours=np.random.normal(loc=4, scale=1))\n",
    "        case 'norm-exp':\n",
    "            current_time += timedelta(hours=np.random.exponential(1 / rate_for_test))\n",
    "    rows.append({\n",
    "        \"case:concept:name\": case_id_str,\n",
    "        \"concept:name\": \"Com\",\n",
    "        \"org:role\": \"Employee\",\n",
    "        \"org:resource\": f\"{resources[random.randint(2, 5)-1]}\",\n",
    "        \"time:timestamp\": current_time\n",
    "    })\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(rows)\n",
    "df[\"time:timestamp\"] = pd.to_datetime(df[\"time:timestamp\"])\n",
    "df = df.sort_values(by=[\"case:concept:name\", \"time:timestamp\"]).reset_index(drop=True)\n",
    "\n",
    "final_states = ['Com']\n",
    "\n",
    "if epsilon>1:\n",
    "    from simulation.unfold_events import rename_repeating_events\n",
    "    df, final_states = rename_repeating_events(df,epsilon,final_states)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e99f03417479c455",
   "metadata": {},
   "source": [
    "# Extract time deltas in desired unit\n",
    "time_diffs = {}\n",
    "for case_id, group in df.groupby(\"case:concept:name\"):\n",
    "    events = group[\"concept:name\"].tolist()\n",
    "    roles = group[\"org:role\"].tolist()\n",
    "    times = group[\"time:timestamp\"].tolist()\n",
    "    for i in range(len(events) - 1):\n",
    "        pair = (events[i], events[i + 1], roles[i+1])\n",
    "        delta_time = (times[i + 1] - times[i]).total_seconds()/3600\n",
    "        time_diffs.setdefault(pair, []).append(delta_time)\n",
    "\n",
    "time_diffs.keys()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "times_dictionary = time_diffs",
   "id": "c82f71f0cc80b8eb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "true_rates = {}\n",
    "for k,v in time_diffs.items():\n",
    "    true_rates[k] = rate_for_test"
   ],
   "id": "9833cc1632877d4c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Resource allocation models",
   "id": "7de4c447eb15bc8e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "role_resources = sim_util.get_detailed_weighted_role(df)",
   "id": "25288e6cda7dbcf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "role_trials = {k:v for k,v in role_resources.items()}",
   "id": "51104babfc4954b5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Time model: Exponential fit and statistical hypothesis tests",
   "id": "fd5bd3f93c12efa2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import combine_pvalues\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import expon, sem, t, entropy, kstest\n",
    "from scipy.special import rel_entr, kl_div\n",
    "from scipy.stats import wasserstein_distance\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def compute_freedman_diaconis_bins(data):\n",
    "    iqr = np.subtract(*np.percentile(data, [75, 25]))\n",
    "    bin_width = 2 * iqr / (n ** (1/3))\n",
    "    return int(np.ceil((np.max(data) - np.min(data)) / bin_width)) if bin_width > 0 else 1\n",
    "\n",
    "# ---- Plot and Compute Distances ----\n",
    "fig, axes = plt.subplots(1, len(time_diffs)+2, figsize=(20, 5))\n",
    "metrics_all = {}\n",
    "\n",
    "data_mean_transition_role_time = {}\n",
    "tuples_to_discard = set()\n",
    "\n",
    "i = 1\n",
    "mean_resource_dfg_times = {}\n",
    "for ax, (pair, deltas) in zip(axes, time_diffs.items()):\n",
    "    deltas = np.array(deltas)\n",
    "\n",
    "    mean_time = deltas.mean() # equivalent to 1/expon.fit(deltas, floc=0)\n",
    "    mean_resource_dfg_times[pair] = mean_time\n",
    "    n = len(set(deltas))\n",
    "    if n > 3:\n",
    "        loc, scale = expon.fit(deltas) # equivalent to the Fitter fit\n",
    "        rate = 1/scale\n",
    "        k,k2,k3 = pair\n",
    "        if k not in data_mean_transition_role_time:\n",
    "            data_mean_transition_role_time[k] = {}\n",
    "        if k2 not in data_mean_transition_role_time[k]:\n",
    "            data_mean_transition_role_time[k][k2] = {}\n",
    "        if k3 not in data_mean_transition_role_time[k][k2]:\n",
    "            data_mean_transition_role_time[k][k2][k3] = {\n",
    "                'lambda': rate\n",
    "            }\n",
    "\n",
    "        # Manual fit\n",
    "        rate_manual = 1 / mean_time\n",
    "        ci_half_width = t.ppf(0.975, df=n-1) * sem(deltas)\n",
    "        lower_rate = 1 / (mean_time + ci_half_width)\n",
    "        upper_rate = 1 / (mean_time - ci_half_width)\n",
    "\n",
    "        # True rate\n",
    "        if true_rates and pair in true_rates:\n",
    "            rate_true = true_rates[pair]\n",
    "\n",
    "        # Histogram\n",
    "        num_bins = compute_freedman_diaconis_bins(deltas)\n",
    "        counts, bin_edges = np.histogram(deltas, bins=num_bins, density=False)\n",
    "        bin_widths = np.diff(bin_edges)\n",
    "        total = np.sum(counts)\n",
    "        hist_probs = counts / total\n",
    "\n",
    "        # Model probabilities over bins\n",
    "        model_probs = expon.cdf(bin_edges[1:], scale=scale) - expon.cdf(bin_edges[:-1], scale=scale)\n",
    "        # eps = 1e-12\n",
    "        test_kl_div = entropy(hist_probs, model_probs)\n",
    "        test2_kl_div = np.sum(kl_div(hist_probs, model_probs))\n",
    "        ks_test, ks_p_value = kstest(deltas, lambda deltas: expon.cdf(deltas,loc,scale))\n",
    "        m = 0.5 * (hist_probs + model_probs)\n",
    "        js_div = 0.5 * (entropy(hist_probs, m) + entropy(model_probs, m))\n",
    "        tv_dist = 0.5 * np.sum(np.abs(hist_probs - model_probs))\n",
    "        w_dist = wasserstein_distance(deltas, expon.rvs(scale=scale, size=len(deltas), random_state=42))\n",
    "\n",
    "        # Save metrics\n",
    "        metrics_all[pair] = {\n",
    "            \"kl_divergence\": test_kl_div,\n",
    "            \"js_divergence\": js_div,\n",
    "            \"total_variation\": tv_dist,\n",
    "            \"wasserstein_distance\": w_dist,\n",
    "            \"ks_test\": ks_test,\n",
    "            \"ks_p_value\": ks_p_value,\n",
    "            \"n\": n\n",
    "        }\n",
    "\n",
    "        # Plot histogram and fits\n",
    "        sns.histplot(deltas, bins=num_bins, stat=\"density\", ax=ax, color=\"skyblue\", label=\"Empirical\")\n",
    "        x_vals = np.linspace(0, max(deltas) * 1.2, 200)\n",
    "        ax.plot(x_vals, expon.pdf(x_vals, scale=scale), linestyle=\"-.\", color=\"purple\",\n",
    "                label=f\"Fitted λ = {rate:.4f}\")\n",
    "        if rate_true:\n",
    "            ax.plot(x_vals, expon.pdf(x_vals, scale=1 / rate_true), linestyle=\"dashed\", color=\"black\",\n",
    "                    label=f\"True λ = {rate_true:.4f}\")\n",
    "        ax.fill_between(x_vals,\n",
    "                        expon.pdf(x_vals, scale=1 / lower_rate),\n",
    "                        expon.pdf(x_vals, scale=1 / upper_rate),\n",
    "                        color=\"gray\", alpha=0.3, label=\"95% CI band\")\n",
    "\n",
    "        ax.set_title(f\"λ{i}: {pair[0]}-{pair[2]}→{pair[1]}\",fontsize=18)\n",
    "        i = i + 1\n",
    "        ax.set_xlabel(f\"Time (hours)\",fontsize=16)\n",
    "        ax.set_ylabel(\"Density\",fontsize=16)\n",
    "        ax.legend()\n",
    "\n",
    "        # Text box with metrics\n",
    "        textstr = 'Metrics:\\n'\n",
    "        textstr += '\\n'.join([\n",
    "            f\"KL: {test_kl_div:.4f}\",\n",
    "            f\"JS: {js_div:.4f}\",\n",
    "            f\"TV: {tv_dist:.4f}\",\n",
    "            f\"W: {w_dist:.4f}\",\n",
    "            f\"KS: {ks_test:.4f}\",\n",
    "            f\"KS-P: {ks_p_value:.4f}\",\n",
    "            f\"N: {n}\"\n",
    "        ])\n",
    "        ax.text(0.98, 0.70, textstr,\n",
    "                transform=ax.transAxes,\n",
    "                fontsize=11,\n",
    "                verticalalignment='top',\n",
    "                horizontalalignment='right',\n",
    "                bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    else:\n",
    "        print(pair)\n",
    "        tuples_to_discard.add(pair)\n",
    "\n",
    "total_n = sum(m[\"n\"] for m in metrics_all.values())\n",
    "\n",
    "# Weighted averages for divergence metrics\n",
    "kl_weighted = sum(m[\"kl_divergence\"] * m[\"n\"] for m in metrics_all.values()) / total_n\n",
    "js_weighted = sum(m[\"js_divergence\"] * m[\"n\"] for m in metrics_all.values()) / total_n\n",
    "\n",
    "# Simple averages for bounded or scale-sensitive distances\n",
    "tv_average = np.mean([m[\"total_variation\"] for m in metrics_all.values()])\n",
    "w_average = np.mean([m[\"wasserstein_distance\"] for m in metrics_all.values()])\n",
    "\n",
    "ks_average = np.mean([m[\"ks_test\"] for m in metrics_all.values()])\n",
    "stat, ks_combined_p = combine_pvalues([m[\"ks_p_value\"] for m in metrics_all.values()])\n",
    "# Final aggregate summary\n",
    "plot_legend = {\n",
    "    \"KL: \": \"Kullback-Leibler divergence\",\n",
    "    \"JS: \": \"Jensen-Shannon entropy\",\n",
    "    \"TV: \": \"Total Variation\",\n",
    "    \"W: \": \"Wasserstein Distance\",\n",
    "    \"KS: \": \"Kolmogorov-Smirnov test\",\n",
    "    \"KS-P: \": \"Kolmogorov-Smirnov p-value\",\n",
    "    \"N: \": \"number of samples\"\n",
    "}\n",
    "aggregate_metrics_title=\"Aggregated fit metrics\"\n",
    "\n",
    "aggregate_metrics = {\n",
    "    \"KL Divergence (weighted)\": kl_weighted,\n",
    "    \"JS Divergence (weighted)\": js_weighted,\n",
    "    \"Total Variation Distance (mean)\": tv_average,\n",
    "    \"Wasserstein Distance (mean)\": w_average,\n",
    "    \"KS Test (mean)\": ks_average,\n",
    "    \"KS p-value (combined fisher)\": ks_combined_p,\n",
    "    \"Total Samples\": total_n\n",
    "}\n",
    "\n",
    "# Print aggregated metrics\n",
    "# print(\"\\n--- Aggregated Metrics ---\")\n",
    "# for key, val in aggregate_metrics.items():\n",
    "#     print(f\"{key}: {val:.4f}\")\n",
    "\n",
    "# ---- Display stats----\n",
    "ax_summary = axes[len(axes)-2]\n",
    "# fig_summary, ax_summary = plt.subplots(figsize=(5, 4))\n",
    "ax_summary.axis(\"off\")\n",
    "\n",
    "def format_dict_to_text(input_dict):\n",
    "    summary_text = '\\n'.join([\n",
    "        f\"{k}: {v:.4f}\" if isinstance(v, float) else f\"{k} {v}\"\n",
    "        for k, v in input_dict.items()\n",
    "    ])\n",
    "    return summary_text\n",
    "\n",
    "ax_summary.text(0.3, 1.1-0.1, \"Legend\",\n",
    "                fontsize=18,\n",
    "                ha=\"center\",\n",
    "                va=\"center\",\n",
    "                bbox=dict(boxstyle=\"round\", facecolor=\"white\", alpha=0.9))\n",
    "ax_summary.text(0.3, 0.82-0.1, format_dict_to_text(plot_legend),\n",
    "                fontsize=12,\n",
    "                ha=\"center\",\n",
    "                va=\"center\",\n",
    "                bbox=dict(boxstyle=\"round\", facecolor=\"white\", alpha=0.9))\n",
    "ax_summary.text(0.3, 0.55-0.1, aggregate_metrics_title,\n",
    "                fontsize=18,\n",
    "                ha=\"center\",\n",
    "                va=\"center\",\n",
    "                bbox=dict(boxstyle=\"round\", facecolor=\"white\", alpha=0.9))\n",
    "ax_summary.text(0.3, 0.25-0.1, format_dict_to_text(aggregate_metrics),\n",
    "                fontsize=12,\n",
    "                ha=\"center\",\n",
    "                va=\"center\",\n",
    "                bbox=dict(boxstyle=\"round\", facecolor=\"white\", alpha=1))\n",
    "\n",
    "# ax_summary.set_title(\"Legend\",fontsize=18)\n",
    "\n",
    "# ---- Display resource allocations----\n",
    "ax_hist = axes[len(axes)-1]\n",
    "# Plot the histogram (bar chart)\n",
    "# fig, ax = plt.subplots(figsize=(8, 5))\n",
    "roles = list(role_resources.keys())\n",
    "values = list(role_resources.values())\n",
    "\n",
    "# Bar chart\n",
    "bars = ax_hist.bar(roles, values, color='skyblue')\n",
    "\n",
    "# Define a top threshold (e.g., 95% of max value for the y-axis)\n",
    "y_max = max(values) * 1.05  # Increase y-limit for spacing\n",
    "ax_hist.set_ylim(0, y_max)\n",
    "threshold = y_max * 0.9\n",
    "\n",
    "# Add point and value label smartly\n",
    "for bar, value in zip(bars, values):\n",
    "    x = bar.get_x() + bar.get_width() / 2\n",
    "    y = bar.get_height()\n",
    "    ax_hist.plot(x, y, 'o', color='red')  # Red dot\n",
    "\n",
    "    # Decide label position\n",
    "    if y > threshold:\n",
    "        va = 'top'\n",
    "        y_offset = -0.08\n",
    "    else:\n",
    "        va = 'bottom'\n",
    "        y_offset = 0.08\n",
    "\n",
    "    ax_hist.text(x, y + y_offset, f\"{value:.2f}\", ha='center', va=va, fontsize=14, color='black')\n",
    "\n",
    "# Labels and grid with increased font size\n",
    "ax_hist.set_xlabel('Roles', fontsize=16)\n",
    "ax_hist.set_ylabel('Number of resources', fontsize=16)\n",
    "ax_hist.tick_params(axis='x', labelsize=14)  # Increase x-axis (role labels) font size\n",
    "ax_hist.tick_params(axis='y', labelsize=12)  # (Optional) Increase y-axis tick label size\n",
    "ax_hist.set_title('Resource allocation', fontsize=18)\n",
    "ax_hist.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/time-fit.png', format=\"png\")\n",
    "plt.show()\n",
    "\n",
    "# Save the plot\n",
    "# plot_filename = \"plots/role-histogram.png\"\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(plot_filename)\n",
    "# plt.show()\n",
    "# plt.close()"
   ],
   "id": "a393a305503108e6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "total = len(times_dictionary)\n",
    "kept = len(times_dictionary) - len(tuples_to_discard)\n",
    "discarded = len(tuples_to_discard)\n",
    "\n",
    "print('Kept:', kept)\n",
    "print('Discarded:', discarded)\n",
    "kept_percent = (kept / total) * 100\n",
    "print(f'Kept %: {kept_percent:.2f}%')"
   ],
   "id": "f6f45731fec3acc4",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4fcb5c01f771f4f6",
   "metadata": {},
   "source": [
    "import pm4py\n",
    "pm4py.write_xes(df, \"test.xes\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Building the ctmc and running it",
   "id": "f6978a863c754ab1"
  },
  {
   "cell_type": "code",
   "id": "e1a301b90d3dd19e",
   "metadata": {},
   "source": [
    "subset_el = pm4py.convert_to_event_log(df)\n",
    "dfg, start_activities, end_activities = pm4py.discover_dfg(subset_el)\n",
    "pm4py.view_dfg(dfg, start_activities, end_activities)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5b13a70b666c2a8a",
   "metadata": {},
   "source": [
    "subset_el = log_parser.add_start_end(subset_el)\n",
    "dfg[\"end\", \"start\"] = 1\n",
    "subset_el = pm4py.convert_to_dataframe(subset_el)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "418f1fe7074ccb93",
   "metadata": {},
   "source": [
    "data_transition_role_frequency = sim_util.get_transition_resource_dict(subset_el)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e84c6508fe0da157",
   "metadata": {},
   "source": [
    "for (e_from,e_to,role) in tuples_to_discard:\n",
    "    if e_from in data_transition_role_frequency:\n",
    "        if e_to in data_transition_role_frequency[e_from]:\n",
    "            if role in data_transition_role_frequency[e_from][e_to]:\n",
    "                data_transition_role_frequency[e_from][e_to].pop(role)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ce44771e0e586256",
   "metadata": {},
   "source": [
    "for e_from in data_transition_role_frequency.keys():\n",
    "    for e_to in data_transition_role_frequency.keys():\n",
    "        if (e_from == 'start' and e_to == 'start') or (e_from == 'end' and e_to == 'end'):\n",
    "            data_transition_role_frequency[e_from].pop(e_to)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9f660e252723ea3d",
   "metadata": {},
   "source": [
    "def remove_empty_keys(d):\n",
    "    \"\"\"Recursively remove empty keys from a three-level nested dictionary.\"\"\"\n",
    "    if not isinstance(d, dict):\n",
    "        return d  # Return non-dict values as they are\n",
    "\n",
    "    cleaned_dict = {}\n",
    "    for key, value in d.items():\n",
    "        if isinstance(value, dict):\n",
    "            cleaned_value = remove_empty_keys(value)  # Recursively clean sub-dictionaries\n",
    "            if cleaned_value:  # Add only if not empty\n",
    "                cleaned_dict[key] = cleaned_value\n",
    "        elif value not in (None, \"\", [], {}, ()):  # Ignore empty values\n",
    "            cleaned_dict[key] = value\n",
    "\n",
    "    return cleaned_dict\n",
    "\n",
    "data_transition_role_frequency = remove_empty_keys(data_transition_role_frequency)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "279afab90356e582",
   "metadata": {},
   "source": [
    "res = {}\n",
    "dfg_input = {}\n",
    "out_frequency = {}\n",
    "data_transition_role_prob = {}\n",
    "resource_dfg_input = {}\n",
    "\n",
    "for k,v in data_transition_role_frequency.items():\n",
    "    if k in ['start','end']:\n",
    "        continue\n",
    "    out_freq = 0\n",
    "    if k not in data_transition_role_prob:\n",
    "        data_transition_role_prob[k] = {}\n",
    "        resource_dfg_input[k] = {}\n",
    "\n",
    "    for k2,v2 in v.items():\n",
    "        if k2 in ['start','end']:\n",
    "            continue\n",
    "        all_freq = 0\n",
    "\n",
    "        if k2 not in data_transition_role_prob[k]:\n",
    "            data_transition_role_prob[k][k2] = {}\n",
    "            resource_dfg_input[k][k2] = {}\n",
    "\n",
    "        if k not in res:\n",
    "            res[k] = {}\n",
    "            dfg_input[k] = {}\n",
    "        if k2 not in res[k]:\n",
    "            for k3,v3 in v2.items():\n",
    "                if k3 not in data_transition_role_prob[k][k2]:\n",
    "                    data_transition_role_prob[k][k2][k3] = v3\n",
    "                    resource_dfg_input[k][k2][k3] = v3\n",
    "                all_freq += v3\n",
    "            res[k][k2] = all_freq\n",
    "            dfg_input[k][k2] = all_freq\n",
    "            out_freq += all_freq\n",
    "        out_frequency[k] = out_freq\n",
    "for k,v in res.items():\n",
    "    for k2,v2 in v.items():\n",
    "        res[k][k2] = res[k][k2]/out_frequency[k]\n",
    "\n",
    "for k,v in data_transition_role_prob.items():\n",
    "    for k2,v2 in v.items():\n",
    "        for k3,v3 in v2.items():\n",
    "            data_transition_role_prob[k][k2][k3] = v3/out_frequency[k]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cd6b38808cd08069",
   "metadata": {},
   "source": [
    "states = set(subset_el['concept:name'].unique()).difference(set(['start','end']))\n",
    "n = len(states)\n",
    "i = 0\n",
    "correspondence = {s:i for s,i in zip(states,range(len(states)))}\n",
    "#TODO: make sure none of the final states have state = 0 in the prism program\n",
    "non_final_states = list(states.difference(set(final_states)))\n",
    "for s in final_states:\n",
    "    if correspondence[s] == 0:\n",
    "        correspondence[s] = correspondence[non_final_states[0]]\n",
    "        correspondence[non_final_states[0]] = 0\n",
    "correspondence"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "gt_data_mean_transition_role_time = deepcopy(data_mean_transition_role_time)\n",
    "\n",
    "def replace_lambda_values(d, new_value):\n",
    "    for key, value in d.items():\n",
    "        if isinstance(value, dict):\n",
    "            replace_lambda_values(value, new_value)\n",
    "        elif key == \"lambda\":\n",
    "            d[key] = new_value\n",
    "\n",
    "replace_lambda_values(gt_data_mean_transition_role_time,0.25)"
   ],
   "id": "b0f2b823e56d297e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "start_states = ['Acc']\n",
    "end_states = ['Com']\n",
    "if epsilon!=1:\n",
    "    start_states = ['Acc1']\n",
    "    end_states = ['Com1']\n",
    "view_resource_dfg(resource_dfg_input,mean_times=mean_resource_dfg_times,start_states=start_states, end_states=end_states,percentage=False)\n",
    "view_non_resource_dfg(dfg_input,start_states=start_states, end_states=end_states,percentage=False)"
   ],
   "id": "7eeeddec1bb597c1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "view_resource_markov_chain(data_transition_role_prob,percentage=True)\n",
    "view_non_resource_markov_chain(res,percentage=True)"
   ],
   "id": "14130e032bc47418",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data_transition_role_frequency",
   "id": "68efe6f1616ab091",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b0c509a74dee7eb1",
   "metadata": {},
   "source": [
    "from simulation.ctmc_frequency import create_prism_program_from_log\n",
    "\n",
    "probabilities = create_prism_program_from_log(\n",
    "                            correspondence,\n",
    "                            final_states,\n",
    "                            data_mean_transition_role_time,\n",
    "                            role_resources,\n",
    "                            data_transition_role_frequency,\n",
    "                            role_trials,\n",
    "                            'ctmc.sm',\n",
    "                            show_print=True)\n",
    "\n",
    "gt_probabilities = create_prism_program_from_log(\n",
    "                            correspondence,\n",
    "                            final_states,\n",
    "                            gt_data_mean_transition_role_time,\n",
    "                            role_resources,\n",
    "                            data_transition_role_frequency,\n",
    "                            role_trials,\n",
    "                            'ctmc-gt.sm')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "prism_program = stormpy.parse_prism_program('ctmc.sm',prism_compat=True,simplify=True)\n",
    "gt_prism_program = stormpy.parse_prism_program('ctmc-gt.sm',prism_compat=True,simplify=True)\n",
    "model = stormpy.build_model(prism_program)\n",
    "gt_model = stormpy.build_model(gt_prism_program)\n",
    "\n",
    "def get_result(model, prism_program):\n",
    "    labels = \"\"\n",
    "    for fs in final_states:\n",
    "        labels += f'\"q_terminal_{fs}\" |'\n",
    "    labels = labels[:-2]\n",
    "    formula_str = f'Tmin=? [F {labels}]'\n",
    "    print(formula_str)\n",
    "    properties = stormpy.parse_properties(formula_str, prism_program)\n",
    "    result = stormpy.model_checking(model, properties[0])\n",
    "    initial_state = model.initial_states[0]\n",
    "    result = result.at(initial_state)\n",
    "    print(f\"Hours: {result}\")\n",
    "    if result<np.inf:\n",
    "        print(f\"Duration: {timedelta(hours=result)}\")\n",
    "    return result\n",
    "\n",
    "result = get_result(model,prism_program)\n",
    "gt_result = get_result(gt_model,gt_prism_program)"
   ],
   "id": "d6fce727b45e682d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Difference between ground truth rate calculation and fitted exponential calculation",
   "id": "39c98301831e10dd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "abs(result - gt_result)",
   "id": "acb195bf9318ea0d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Resource Regression Analysis",
   "id": "89e12f766c3db2c0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import random\n",
    "\n",
    "durations = []\n",
    "# x = list(range(1,50))\n",
    "samples = 500\n",
    "for i in range(samples):\n",
    "    regression_role_trials = {}\n",
    "    for k,v in role_trials.items():\n",
    "        # random_resource_number = abs(random.gauss(v,v/2))\n",
    "        random_resource_number = abs(random.uniform(v/2,v**2))\n",
    "        regression_role_trials[k] = random_resource_number\n",
    "    probabilities = create_prism_program_from_log(\n",
    "                            correspondence,\n",
    "                            final_states,\n",
    "                            data_mean_transition_role_time,\n",
    "                            role_resources,\n",
    "                            data_transition_role_frequency,\n",
    "                            regression_role_trials,\n",
    "                            'ctmc-temp.sm')\n",
    "    prism_program = stormpy.parse_prism_program('ctmc-temp.sm', prism_compat=True, simplify=True)\n",
    "    model = stormpy.build_model(prism_program)\n",
    "    labels = \"\"\n",
    "    for fs in final_states:\n",
    "        labels += f'\"q_terminal_{fs}\" |'\n",
    "    labels = labels[:-2]\n",
    "\n",
    "    formula_str = f'Tmin=? [F {labels}]'\n",
    "    properties = stormpy.parse_properties(formula_str, prism_program)\n",
    "    result = stormpy.model_checking(model, properties[0])\n",
    "    initial_state = model.initial_states[0]\n",
    "    result = result.at(initial_state)\n",
    "    durations.append({**regression_role_trials, \"duration\": result})\n",
    "    # print(f'{i}/{samples}')"
   ],
   "id": "153b9fa0424a927",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "durations_df = pd.DataFrame(durations)\n",
    "durations_df"
   ],
   "id": "85f6a30ca6be1715",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Example: Load your DataFrame\n",
    "# df = pd.read_csv(\"your_data.csv\")\n",
    "\n",
    "def run_linear_regression(df, target_column, fit_intercept=True):\n",
    "    # Split into X (features) and y (target)\n",
    "    X = df.drop(columns=[target_column])\n",
    "    y = df[target_column]\n",
    "\n",
    "    # Fit model\n",
    "    model = LinearRegression(fit_intercept=fit_intercept)\n",
    "    model.fit(X, y)\n",
    "\n",
    "    # Print model coefficients\n",
    "    intercept = model.intercept_\n",
    "    coef = model.coef_\n",
    "\n",
    "    print(\"Intercept:\", intercept if fit_intercept else \"Not used\")\n",
    "    print(\"Coefficients:\")\n",
    "    for col, weight in zip(X.columns, coef):\n",
    "        print(f\"{col}: {weight:.4f}\")\n",
    "\n",
    "    return model, X.columns, coef\n",
    "\n",
    "def rank_features_by_importance(X, coef):\n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': X,\n",
    "        'Coefficient': coef,\n",
    "        'Importance (abs)': abs(coef)\n",
    "    })\n",
    "    return importance_df.sort_values(by='Importance (abs)', ascending=False)\n",
    "\n",
    "# Run regression\n",
    "model, features, coefs = run_linear_regression(durations_df, 'duration', fit_intercept=True)\n",
    "\n",
    "# Rank features\n",
    "ranking = rank_features_by_importance(features, coefs)\n",
    "print(\"\\nFeature Ranking:\\n\", ranking)"
   ],
   "id": "2c4d60f2626ffc3e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# pm4py",
   "id": "8126c342493c9bbf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mean, median, margin_of_error = sim_util.get_pm4py_reference_times(subset_el)\n",
    "print(timedelta(seconds=median))\n",
    "print(timedelta(seconds=mean))\n",
    "print(timedelta(seconds=margin_of_error))"
   ],
   "id": "658dbb727a7c73b0",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
