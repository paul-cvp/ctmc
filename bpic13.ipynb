{
 "cells": [
  {
   "cell_type": "code",
   "id": "a2954fc60f66cfd",
   "metadata": {},
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {},
   "source": [
    "import pm4py\n",
    "import scipy\n",
    "import stormpy\n",
    "import datetime\n",
    "import numpy as np\n",
    "from fitter import Fitter"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e4a66b53b5c08a0e",
   "metadata": {},
   "source": [
    "from simulation.markov_models import log_parser\n",
    "from simulation.markov_chain import apply as mc_apply\n",
    "from simulation.markov_chain_vis import view_markov_chain, view_resource_markov_chain, view_non_resource_markov_chain\n",
    "import simulation.util as sim_util"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "523329f3b0437457",
   "metadata": {},
   "source": [
    "## Load event log and clean roles"
   ]
  },
  {
   "cell_type": "code",
   "id": "708bf878eb53cba6",
   "metadata": {},
   "source": [
    "event_log = pm4py.read_xes('BPI_Challenge_2013_incidents.xes.gz')\n",
    "event_log = event_log.sort_values(['case:concept:name','time:timestamp'])\n",
    "number_of_traces = event_log['case:concept:name'].nunique()\n",
    "subset_el = event_log[['case:concept:name','concept:name','time:timestamp','org:resource','org:role']]\n",
    "subset_el['org:role'] = subset_el['org:role'].fillna('nan_1').apply(lambda x: x.split('_')[0])\n",
    "subset_el['org:role'] = subset_el['org:role'].replace({'C':'C1','D':'D1','E':'E1'})"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "bc949809c2ee45c",
   "metadata": {},
   "source": [
    "## Define the final states\n",
    "The final states need to be reachable from the start states according to the DFG.\n",
    "There can be many, but all of them have to point towards the end state."
   ]
  },
  {
   "cell_type": "code",
   "id": "5a5008bdef7ebcc0",
   "metadata": {},
   "source": [
    "final_states = ['Completed']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "86b02cea141b81dc",
   "metadata": {},
   "source": [
    "subset_el = pm4py.read_xes('test.xes')\n",
    "final_states = ['End']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ed94949abb6193e0",
   "metadata": {},
   "source": [
    "# Discovery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592e2ebe780fd2b6",
   "metadata": {},
   "source": [
    "## Start Control Flow Model: Directly Follows Graph"
   ]
  },
  {
   "cell_type": "code",
   "id": "5d8063c3ed1f8c24",
   "metadata": {},
   "source": [
    "subset_el = pm4py.convert_to_event_log(subset_el)\n",
    "subset_el = log_parser.add_start_end(subset_el)\n",
    "dfg, start_activities, end_activities = pm4py.discover_dfg(subset_el)\n",
    "dfg[\"end\", \"start\"] = 1"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "19550dfef818d7f2",
   "metadata": {},
   "source": [
    "pm4py.view_dfg(dfg, start_activities, end_activities)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f71a48aa232f64be",
   "metadata": {},
   "source": [
    "subset_el = pm4py.convert_to_dataframe(subset_el)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "94f786b6a5ec351c",
   "metadata": {},
   "source": [
    "## (Optional step) Proportional filtering"
   ]
  },
  {
   "cell_type": "code",
   "id": "5292219cd2413243",
   "metadata": {},
   "source": [
    "#TODO: remove arrows in the dfg that account for less than x percent of transitions"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2395d91d02dce754",
   "metadata": {},
   "source": [
    "## Extract the inputs to the ctmc from the event log"
   ]
  },
  {
   "cell_type": "code",
   "id": "2ccab1ed5fd38911",
   "metadata": {},
   "source": [
    "data_transition_role_frequency = sim_util.get_transition_resource_dict(subset_el)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "83c6987874ee7956",
   "metadata": {},
   "source": [
    "from simulation.timings import Timings\n",
    "\n",
    "mine_declaratively = True\n",
    "if mine_declaratively:\n",
    "    timings = Timings()\n",
    "    resource_input_array = timings.create_resource_input_array_from_log(subset_el)\n",
    "    res_timings = timings.get_timings_per_resource(subset_el, resource_input_array)\n",
    "    times_dictionary = res_timings\n",
    "else:\n",
    "    timings = Timings()\n",
    "    times_dictionary = timings.extract_resource_times_with_future(subset_el)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "32c5a549db6d766b",
   "metadata": {},
   "source": [
    "data_mean_transition_role_time = {}\n",
    "tuples_to_discard = set()\n",
    "for k,v in data_transition_role_frequency.items():\n",
    "    if k in ['start','end']:\n",
    "        continue\n",
    "    for k2,v2 in v.items():\n",
    "        if k2 in ['start','end']:\n",
    "            continue\n",
    "        all_freq = 0\n",
    "        for k3,v3 in v2.items():\n",
    "            all_freq += v3\n",
    "            if (k,k2,k3) in times_dictionary:\n",
    "                times = times_dictionary[(k,k2,k3)]\n",
    "                times = np.array(times)\n",
    "                times = times/3600\n",
    "                times = times[times != 0]\n",
    "                if len(times) > 1: # only take times that have more than 1 value\n",
    "                    expon_loc, expon_scale = scipy.stats.expon.fit(times)\n",
    "\n",
    "                    # f = Fitter(times, distributions=['expon'])\n",
    "                    # f.fit()\n",
    "                    # best = f.get_best()['expon']\n",
    "                    # expon_loc_fitter, expon_scale_fitter = best['loc'], best['scale']\n",
    "\n",
    "                    if expon_scale>0: # do not take times that cannot be fit into an exponential\n",
    "                        rate = 1/expon_scale\n",
    "                        if k not in data_mean_transition_role_time:\n",
    "                            data_mean_transition_role_time[k] = {}\n",
    "                        if k2 not in data_mean_transition_role_time[k]:\n",
    "                            data_mean_transition_role_time[k][k2] = {}\n",
    "                        if k3 not in data_mean_transition_role_time[k][k2]:\n",
    "                            data_mean_transition_role_time[k][k2][k3] = {\n",
    "                                # 'loc': expon_loc_fitter,\n",
    "                                # 'scale': expon_scale_fitter,\n",
    "                                'loc': expon_loc,\n",
    "                                'scale': expon_scale,\n",
    "                                'lambda': rate\n",
    "                            }\n",
    "                    else:\n",
    "                        print(k,k2,k3)\n",
    "                        tuples_to_discard.add((k,k2,k3))\n",
    "                        print(times)\n",
    "                else:\n",
    "                    print(k,k2,k3)\n",
    "                    tuples_to_discard.add((k,k2,k3))\n",
    "                    print(times)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a54a4d8b174bef2c",
   "metadata": {},
   "source": [
    "for (e_from,e_to,role) in tuples_to_discard:\n",
    "    if e_from in data_transition_role_frequency:\n",
    "        if e_to in data_transition_role_frequency[e_from]:\n",
    "            if role in data_transition_role_frequency[e_from][e_to]:\n",
    "                data_transition_role_frequency[e_from][e_to].pop(role)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f9fc080a502a7bd8",
   "metadata": {},
   "source": [
    "for e_from in data_transition_role_frequency.keys():\n",
    "    for e_to in data_transition_role_frequency.keys():\n",
    "        if (e_from == 'start' and e_to == 'start') or (e_from == 'end' and e_to == 'end'):\n",
    "            data_transition_role_frequency[e_from].pop(e_to)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "22ae151f19603f5",
   "metadata": {},
   "source": [
    "def remove_empty_keys(d):\n",
    "    \"\"\"Recursively remove empty keys from a three-level nested dictionary.\"\"\"\n",
    "    if not isinstance(d, dict):\n",
    "        return d  # Return non-dict values as they are\n",
    "\n",
    "    cleaned_dict = {}\n",
    "    for key, value in d.items():\n",
    "        if isinstance(value, dict):\n",
    "            cleaned_value = remove_empty_keys(value)  # Recursively clean sub-dictionaries\n",
    "            if cleaned_value:  # Add only if not empty\n",
    "                cleaned_dict[key] = cleaned_value\n",
    "        elif value not in (None, \"\", [], {}, ()):  # Ignore empty values\n",
    "            cleaned_dict[key] = value\n",
    "\n",
    "    return cleaned_dict\n",
    "\n",
    "data_transition_role_frequency = remove_empty_keys(data_transition_role_frequency)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "437410b664de0908",
   "metadata": {},
   "source": [
    "role_resources = sim_util.get_detailed_weighted_role(subset_el)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f5b2dd9b2eccc954",
   "metadata": {},
   "source": [
    "role_trials = {k:int(v) for k,v in role_resources.items()}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1e7fc29e0feaa924",
   "metadata": {},
   "source": [
    "res = {}\n",
    "out_frequency = {}\n",
    "data_transition_role_prob = {}\n",
    "\n",
    "for k,v in data_transition_role_frequency.items():\n",
    "    if k in ['start','end']:\n",
    "        continue\n",
    "    out_freq = 0\n",
    "    if k not in data_transition_role_prob:\n",
    "        data_transition_role_prob[k] = {}\n",
    "\n",
    "    for k2,v2 in v.items():\n",
    "        if k2 in ['start','end']:\n",
    "            continue\n",
    "        all_freq = 0\n",
    "\n",
    "        if k2 not in data_transition_role_prob[k]:\n",
    "            data_transition_role_prob[k][k2] = {}\n",
    "\n",
    "        if k not in res:\n",
    "            res[k] = {}\n",
    "        if k2 not in res[k]:\n",
    "            for k3,v3 in v2.items():\n",
    "                if k3 not in data_transition_role_prob[k][k2]:\n",
    "                    data_transition_role_prob[k][k2][k3] = v3\n",
    "                all_freq += v3\n",
    "            res[k][k2] = all_freq\n",
    "            out_freq += all_freq\n",
    "        out_frequency[k] = out_freq\n",
    "\n",
    "for k,v in res.items():\n",
    "    for k2,v2 in v.items():\n",
    "        res[k][k2] = res[k][k2]/out_frequency[k]\n",
    "\n",
    "for k,v in data_transition_role_prob.items():\n",
    "    for k2,v2 in v.items():\n",
    "        for k3,v3 in v2.items():\n",
    "            data_transition_role_prob[k][k2][k3] = v3/out_frequency[k]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "523295f3c18f69a7",
   "metadata": {},
   "source": [
    "view_resource_markov_chain(data_transition_role_prob)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8a2f0b2aeaad1a55",
   "metadata": {},
   "source": [
    "semi_markov_json = mc_apply(subset_el)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bcbf37cf57aa3322",
   "metadata": {},
   "source": [
    "view_markov_chain(semi_markov_json)\n",
    "view_non_resource_markov_chain(res)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "73ec8d92a3e2f92a",
   "metadata": {},
   "source": [
    "role_resources"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8fc37ff33a8c7a75",
   "metadata": {},
   "source": [
    "states = set(subset_el['concept:name'].unique()).difference(set(['start','end']))\n",
    "n = len(states)\n",
    "i = 0\n",
    "correspondence = {s:i for s,i in zip(states,range(len(states)))}\n",
    "#TODO: make sure none of the final states have state = 0 in the prism program\n",
    "non_final_states = list(states.difference(set(final_states)))\n",
    "for s in final_states:\n",
    "    if correspondence[s] == 0:\n",
    "        correspondence[s] = correspondence[non_final_states[0]]\n",
    "        correspondence[non_final_states[0]] = 0\n",
    "correspondence"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "74035543add45614",
   "metadata": {},
   "source": [
    "## Analysis for resource allocation"
   ]
  },
  {
   "cell_type": "code",
   "id": "d404cefc93d55bf1",
   "metadata": {},
   "source": [
    "role_resources"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2e424f3e1b9b4ed9",
   "metadata": {},
   "source": [
    "role_trials = role_resources\n",
    "role_trials"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4098c1ac49e6fba",
   "metadata": {},
   "source": [
    "from simulation.ctmc import create_prism_program_from_log\n",
    "\n",
    "probabilities = create_prism_program_from_log(\n",
    "                            correspondence,\n",
    "                            final_states,\n",
    "                            data_mean_transition_role_time,\n",
    "                            role_resources,\n",
    "                            data_transition_role_frequency,\n",
    "                            role_trials,\n",
    "                            'ctmc.sm')\n",
    "# print(probabilities)\n",
    "prism_program = stormpy.parse_prism_program('ctmc.sm',prism_compat=True,simplify=True)\n",
    "model = stormpy.build_model(prism_program)\n",
    "# print(\"Number of states: {}\".format(model.nr_states))\n",
    "# print(\"Number of transitions: {}\".format(model.nr_transitions))\n",
    "# print(\"Labels: {}\".format(model.labeling.get_labels()))\n",
    "labels = \"\"\n",
    "for fs in final_states:\n",
    "    labels += f'\"q_terminal_{fs}\" |'\n",
    "labels = labels[:-2]\n",
    "\n",
    "formula_str = f'Tmin=? [F {labels}]'\n",
    "properties = stormpy.parse_properties(formula_str, prism_program)\n",
    "result = stormpy.model_checking(model, properties[0])\n",
    "initial_state = model.initial_states[0]\n",
    "result = result.at(initial_state)\n",
    "print(f\"Hours: {result}\")\n",
    "if result<np.inf:\n",
    "    print(f\"Duration: {datetime.timedelta(hours=result)}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "be7c95386ee3c55b",
   "metadata": {},
   "source": [
    "mean, median, margin_of_error = sim_util.get_pm4py_reference_times(subset_el)\n",
    "print(datetime.timedelta(seconds=median))\n",
    "print(datetime.timedelta(seconds=mean))\n",
    "print(datetime.timedelta(seconds=margin_of_error))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3b9f6542c2ca2461",
   "metadata": {},
   "source": [
    "view_non_resource_markov_chain(probabilities)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "79b8ab3354db1812",
   "metadata": {},
   "source": [
    "import random\n",
    "\n",
    "durations = []\n",
    "x = list(range(1,50))\n",
    "samples = 500\n",
    "for i in range(samples):\n",
    "    role_trials = {\n",
    "        'R1': random.choice(x)\n",
    "        # \"A2\": random.choice(x),\n",
    "        # \"C1\": random.choice(x),\n",
    "        # \"D1\": random.choice(x),\n",
    "        # \"E1\": random.choice(x),\n",
    "        # \"V3\": random.choice(x),\n",
    "        # \"nan\": random.choice(x)\n",
    "    }\n",
    "    print(role_trials)\n",
    "    probabilities = create_prism_program_from_log(\n",
    "                            correspondence,\n",
    "                            final_states,\n",
    "                            data_mean_transition_role_time,\n",
    "                            role_resources,\n",
    "                            data_transition_role_frequency,\n",
    "                            role_trials,\n",
    "                            'ctmc.sm')\n",
    "    prism_program = stormpy.parse_prism_program('ctmc.sm', prism_compat=True, simplify=True)\n",
    "    model = stormpy.build_model(prism_program)\n",
    "    labels = \"\"\n",
    "    for fs in final_states:\n",
    "        labels += f'\"q_terminal_{fs}\" |'\n",
    "    labels = labels[:-2]\n",
    "\n",
    "    formula_str = f'Tmin=? [F {labels}]'\n",
    "    properties = stormpy.parse_properties(formula_str, prism_program)\n",
    "    result = stormpy.model_checking(model, properties[0])\n",
    "    initial_state = model.initial_states[0]\n",
    "    result = result.at(initial_state)\n",
    "    durations.append({**role_trials, \"duration\": result})\n",
    "    print(f'{i}/{samples}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4d07c58a3e9ebae2",
   "metadata": {},
   "source": [
    "## Find the under estimation coeficient for the specific log"
   ]
  },
  {
   "cell_type": "code",
   "id": "1c9e45507bd9d6f8",
   "metadata": {},
   "source": [
    "from copy import deepcopy\n",
    "from pm4py.algo.filtering.log.variants import variants_filter"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6f2afc8ee61e3346",
   "metadata": {},
   "source": [
    "scales = [2**i for i in range(-5, 6)]  # -5 to 5 gives 1/32x to 32x\n",
    "labels = [f\"{s}x\" if s >= 1 else f\"1/{int(1/s)}x\" for s in scales]\n",
    "sc_data = {}\n",
    "for scale, label in zip(scales, labels):\n",
    "    print(label)\n",
    "    el = sim_util.scale_event_log_time(deepcopy(subset_el), multiplicity=scale)\n",
    "    sc_data[label] = el\n",
    "    filtered_el = pm4py.convert_to_dataframe(variants_filter.filter_log_variants_percentage(deepcopy(el),percentage=0.8))\n",
    "    sc_data[f'filtered-{label}'] = filtered_el"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9281d935025d072",
   "metadata": {},
   "source": [
    "sc_df = sim_util.sanity_check(sc_data,final_states)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "73f31da17175f6c7",
   "metadata": {},
   "source": [
    "sc_df[['label','ref-mean','ref-median','analysis-time','offset']]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "79c1c7899af88297",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "el = []\n",
    "el_errors = []\n",
    "ctmc_el = []\n",
    "el_filtered = []\n",
    "el_filtered_errors = []\n",
    "ctmc_elf = []\n",
    "x = [i for i in range(len(scales))]\n",
    "for i,row in sc_df.iterrows():\n",
    "    if str(row['label']).startswith('filtered'):\n",
    "        el_filtered.append(row['ref-median'].total_seconds()//3600)\n",
    "        el_filtered_errors.append(row['ref-std'].total_seconds()//3600)\n",
    "        ctmc_elf.append(row['analysis-time'].total_seconds()//3600)\n",
    "    else:\n",
    "        el.append(row['ref-median'].total_seconds()//3600)\n",
    "        el_errors.append(row['ref-std'].total_seconds()//3600)\n",
    "        ctmc_el.append(row['analysis-time'].total_seconds()//3600)\n",
    "\n",
    "el = np.array(el)\n",
    "el_errors = np.array(el_errors)\n",
    "ctmc_el = np.array(ctmc_el)\n",
    "el_filtered = np.array(el_filtered)\n",
    "el_filtered_errors = np.array(el_filtered_errors)\n",
    "ctmc_elf = np.array(ctmc_elf)\n",
    "\n",
    "log_el = np.log(el)\n",
    "log_el_errors = np.log(el_errors)\n",
    "log_ctmc_el = np.log(ctmc_el)\n",
    "log_el_filtered = np.log(el_filtered)\n",
    "log_el_filtered_errors = np.log(el_filtered_errors)\n",
    "log_ctmc_elf = np.log(ctmc_elf)\n",
    "\n",
    "plt.figure(1,(16,4))\n",
    "\n",
    "plt.scatter(x,log_el, color='r',marker='.')\n",
    "plt.plot(x,log_el,label='el median',color='r',linestyle='-', marker='.')\n",
    "plt.fill_between(x, log_el - log_el_errors, log_el + log_el_errors, alpha=0.2, color='r')\n",
    "\n",
    "plt.scatter(x,log_ctmc_el, color='b',marker='v')\n",
    "plt.plot(x,log_ctmc_el,label='ctmc-el', color='b',marker='v',linestyle='--')\n",
    "\n",
    "plt.scatter(x,log_el_filtered, color='g',marker='s',s=10)\n",
    "plt.plot(x,log_el_filtered,label='el-filtered median', color='g',marker='s',linestyle=':')\n",
    "plt.fill_between(x, log_el_filtered - log_el_filtered_errors, log_el_filtered + log_el_filtered_errors, alpha=0.2, color='g')\n",
    "\n",
    "plt.scatter(x,log_ctmc_elf, color='orange',marker='*',)\n",
    "plt.plot(x,log_ctmc_elf,label='ctmc-elf', color='orange',marker='*',linestyle='-.')\n",
    "\n",
    "plt.xticks(x,labels)\n",
    "plt.xlabel('event log duration time scale')\n",
    "plt.ylabel('duration (hours,log scale)')\n",
    "plt.title('BIC 13 log')\n",
    "plt.legend()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "53848139b89a8226",
   "metadata": {},
   "source": [
    "## Find regression coeficients"
   ]
  },
  {
   "cell_type": "code",
   "id": "6a9f24bf9fd5a287",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "\n",
    "durations_df = pd.DataFrame(durations)\n",
    "durations_df"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b5def09f0c5a5698",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "994831bb54a16ba9",
   "metadata": {},
   "source": [
    "## Save the configurations"
   ]
  },
  {
   "cell_type": "code",
   "id": "8d7d4b38f7b13405",
   "metadata": {},
   "source": [
    "import json\n",
    "\n",
    "with open('mean_transition_role_time.json', 'w') as file:\n",
    "    json.dump(data_mean_transition_role_time, file, indent=4)\n",
    "\n",
    "with open('role_number_of_resources.json', 'w') as file:\n",
    "    json.dump(role_resources, file, indent=4)\n",
    "\n",
    "with open('transition_role_frequency.json', 'w') as file:\n",
    "    json.dump(data_transition_role_frequency, file, indent=4)\n",
    "\n",
    "role_trials = {k:int(v) for k,v in role_resources.items()}\n",
    "with open('role_trials.json', 'w') as file:\n",
    "    json.dump(role_trials, file, indent=4)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "213f1c6162c6a04f",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142b83db1b21c0a5",
   "metadata": {},
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "code",
   "id": "30e5b23e441c32f6",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9c17c4ad07ed6ae4",
   "metadata": {},
   "source": [
    "## Analyze timings for specific roles\n",
    "TODO: run a ks or chi-square test between the fitted functions to analyze the goodness of fit"
   ]
  },
  {
   "cell_type": "code",
   "id": "6c952c92d5934134",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import fitter\n",
    "from simulation.markov_models.fit_distribution import fit_gauss\n",
    "\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import entropy as kl_div"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "56774ee5484decc2",
   "metadata": {},
   "source": [
    "eval_functions = pd.DataFrame()\n",
    "\n",
    "seed=None\n",
    "\n",
    "for k, v in times_dictionary.items():\n",
    "    s1 = k[0]\n",
    "    s2 = k[1]\n",
    "    role = k[2]\n",
    "    v = np.array(v)\n",
    "    v = v // 3600\n",
    "    # do we remove 0 values?\n",
    "    v = v[v != 0]\n",
    "    #Note: on invalid values the fitting will return NaN. This means there was no fit.\n",
    "    if len(v) > 1:# and role in ['V3']:\n",
    "        x = [i for i in range(len(v))]\n",
    "\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(10, 4))\n",
    "\n",
    "        f = fitter.Fitter(v,distributions=fitter.get_common_distributions())\n",
    "        f.fit()\n",
    "        best_dist, fitted_params = f.get_best().popitem()\n",
    "        best_two_summary = f.summary(Nbest=2,plot=True,lw=1)\n",
    "\n",
    "        test_func = getattr(scipy.stats, best_dist)\n",
    "        test_res = test_func.pdf(x, **fitted_params)\n",
    "        best_two_summary.loc[best_dist,'kl_div'] = kl_div(test_res,v)\n",
    "        second_best = best_two_summary.index[1]\n",
    "        test_func = getattr(scipy.stats, second_best)\n",
    "        test_res = test_func.pdf(x, *f.fitted_param[second_best])\n",
    "        best_two_summary.loc[second_best,'kl_div'] = kl_div(test_res,v)\n",
    "\n",
    "        kde = sm.nonparametric.KDEUnivariate(v)\n",
    "        kde.fit(bw=4, kernel='gau')  # Estimate the densities\n",
    "        multi_gauss = fit_gauss(kde.support, kde.density, v)\n",
    "        multi_gauss.plot_mult_gauss(x,label='multi-gauss',color='g')\n",
    "        ks_stat, ks_pval, kl_divergence = multi_gauss.fitted_results(v)\n",
    "        best_two_summary.loc['multi-gauss'] = [np.inf,np.inf,np.inf,kl_divergence,ks_stat,ks_pval]\n",
    "\n",
    "        f = fitter.Fitter(v,distributions=['expon'])\n",
    "        f.fit()\n",
    "\n",
    "        f.plot_pdf(names=['expon'],lw=3)\n",
    "        expon_summary = f.summary(Nbest=1,plot=False)\n",
    "        best_expon, fitted_expon = f.get_best().popitem()\n",
    "        res = stats.expon.pdf(x, **fitted_expon)\n",
    "        expon_summary.loc['expon','kl_div'] = kl_div(res,v)\n",
    "        expon_summary.rename({'expon':'_expon'},axis=0,inplace=True)\n",
    "\n",
    "        # plt.xlim([0,500])\n",
    "        plt.title(f'{s1}-{role}->{s2}')\n",
    "        plt.legend(labels=[f'Best fit {best_two_summary.index[0]}',f'Second best fit {best_two_summary.index[1]}','multi-gauss',f'CtMC Exponential'])\n",
    "        plt.savefig(f\"/home/vco/Writing/simulation/figs/timeeval/{s1}-{role}-{s2}.png\",format='png',pad_inches=0)\n",
    "        plt.show()\n",
    "\n",
    "        fit_summary = pd.concat([expon_summary, best_two_summary])\n",
    "        fit_summary['from'] = s1\n",
    "        fit_summary['to'] = s2\n",
    "        fit_summary['role'] = role\n",
    "        eval_functions = pd.concat([eval_functions,fit_summary])\n",
    "        # break"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "73711adf4d11b7f7",
   "metadata": {},
   "source": [
    "kl_div_eval = deepcopy(eval_functions[['kl_div','from','role','to']])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3f0e5ca6d194da9e",
   "metadata": {},
   "source": [
    "clean_kl_div_eval = kl_div_eval[(kl_div_eval['from']!='start') & (kl_div_eval['kl_div'].notna())]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "511603b11e17266e",
   "metadata": {},
   "source": [
    "clean_kl_div_eval['kl_div'].groupby(clean_kl_div_eval.index).mean()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ee2b9ee4883036ea",
   "metadata": {},
   "source": [
    "kl_div_res = clean_kl_div_eval.groupby(clean_kl_div_eval.index).apply(lambda x: x['kl_div'].tolist()).to_dict()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2611622cb12303b2",
   "metadata": {},
   "source": [
    "kl_divergence_values = kl_div_res['_expon']\n",
    "print(kl_divergence_values)\n",
    "kl_divergence_average = np.mean(list(kl_divergence_values))\n",
    "print(\"KL-divergence average:\")\n",
    "print(kl_divergence_average)\n",
    "kl_divergence_interval = stats.t.interval(0.95, df=len(kl_divergence_values) - 1,\n",
    "                                       loc=np.mean(list(kl_divergence_values)),\n",
    "                                       scale=stats.sem(list(kl_divergence_values)))\n",
    "print(\"KL-divergence interval:\")\n",
    "print(kl_divergence_interval[1] - kl_divergence_average)\n",
    "print()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cccca5a580c279fd",
   "metadata": {},
   "source": [
    "kl_divergence_values = kl_div_res['multi-gauss']\n",
    "print(kl_divergence_values)\n",
    "kl_divergence_average = np.mean(list(kl_divergence_values))\n",
    "print(\"KL-divergence average:\")\n",
    "print(kl_divergence_average)\n",
    "kl_divergence_interval = stats.t.interval(0.95, df=len(kl_divergence_values) - 1,\n",
    "                                       loc=np.mean(list(kl_divergence_values)),\n",
    "                                       scale=stats.sem(list(kl_divergence_values)))\n",
    "print(\"KL-divergence interval:\")\n",
    "print(kl_divergence_interval[1] - kl_divergence_average)\n",
    "print()"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
