{
 "cells": [
  {
   "cell_type": "code",
   "id": "72a5867161b718bf",
   "metadata": {},
   "source": [
    "from copy import deepcopy\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b19b2bc1be1df99a",
   "metadata": {},
   "source": [
    "import pm4py\n",
    "import scipy\n",
    "import stormpy\n",
    "from copy import deepcopy\n",
    "import numpy as np"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "13bcc2fe638199ac",
   "metadata": {},
   "source": [
    "from simulation.markov_models import log_parser\n",
    "from simulation.markov_chain import apply as mc_apply\n",
    "from simulation.markov_chain_vis import view_markov_chain, view_resource_markov_chain, view_non_resource_markov_chain\n",
    "import simulation.util as sim_util"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bd8dab6828d51878",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import expon, sem, t\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Simulation parameters\n",
    "np.random.seed(42)\n",
    "num_traces = 1000\n",
    "event_labels = [\"Start\", \"Middle\", \"End\"]\n",
    "rate_start_middle = 0.25  # events per hour\n",
    "rate_middle_end = 0.25    # events per hour\n",
    "rate_start_end = 0.25 # events per hour\n",
    "true_rates = {\n",
    "    (\"Start\", \"Middle\"): rate_start_middle,\n",
    "    (\"Middle\", \"End\"): rate_middle_end,\n",
    "    (\"Start\", \"End\"): rate_middle_end\n",
    "}\n",
    "\n",
    "# Time unit configuration: choose \"seconds\" or \"hours\"\n",
    "time_unit = \"hours\"  # or \"seconds\"\n",
    "time_factor = 1 if time_unit == \"seconds\" else 1 / 3600  # seconds to chosen unit\n",
    "\n",
    "# Generate synthetic event log\n",
    "rows = []\n",
    "for case_id in range(1, num_traces + 1):\n",
    "    current_time = datetime.now()\n",
    "    case_id_str = str(case_id)\n",
    "\n",
    "    rows.append({\n",
    "        \"case:concept:name\": case_id_str,\n",
    "        \"concept:name\": \"Start\",\n",
    "        \"org:role\": \"R1\",\n",
    "        \"org:resource\": \"R1\",\n",
    "        \"time:timestamp\": current_time\n",
    "    })\n",
    "    go_middle = bool(random.getrandbits(1))\n",
    "    number_of_times = int(random.uniform(1, 5))\n",
    "    if go_middle:\n",
    "        for repetition in range(number_of_times):\n",
    "            # current_time += timedelta(hours=np.random.normal(loc=8.0, scale=1.0))\n",
    "            current_time += timedelta(seconds=np.random.exponential(3600 / rate_start_middle))  # convert hours to seconds\n",
    "\n",
    "            rows.append({\n",
    "                \"case:concept:name\": case_id_str,\n",
    "                \"concept:name\": \"Middle\",\n",
    "                \"org:role\": \"R1\",\n",
    "                \"org:resource\": \"R1\",\n",
    "                \"time:timestamp\": current_time\n",
    "            })\n",
    "\n",
    "    # if not go_middle:\n",
    "    current_time += timedelta(seconds=np.random.exponential(3600 / rate_middle_end))\n",
    "    # current_time += timedelta(hours=4)\n",
    "    rows.append({\n",
    "        \"case:concept:name\": case_id_str,\n",
    "        \"concept:name\": \"End\",\n",
    "        \"org:role\": \"R1\",\n",
    "        \"org:resource\": \"R1\",\n",
    "        \"time:timestamp\": current_time\n",
    "    })\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(rows)\n",
    "df[\"time:timestamp\"] = pd.to_datetime(df[\"time:timestamp\"])\n",
    "df = df.sort_values(by=[\"case:concept:name\", \"time:timestamp\"]).reset_index(drop=True)\n",
    "\n",
    "# Extract time deltas in desired unit\n",
    "time_diffs = {}\n",
    "for case_id, group in df.groupby(\"case:concept:name\"):\n",
    "    events = group[\"concept:name\"].tolist()\n",
    "    times = group[\"time:timestamp\"].tolist()\n",
    "    for i in range(len(events) - 1):\n",
    "        pair = (events[i], events[i + 1])\n",
    "        delta_time = (times[i + 1] - times[i]).total_seconds() * time_factor\n",
    "        time_diffs.setdefault(pair, []).append(delta_time)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e99f03417479c455",
   "metadata": {},
   "source": [
    "time_diffs.keys()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "301c7719a5577b13",
   "metadata": {},
   "source": [
    "# Plot histogram and exponential fits\n",
    "fig, axes = plt.subplots(1, len(time_diffs), figsize=(14, 5))\n",
    "\n",
    "for ax, (pair, deltas) in zip(axes, time_diffs.items()):\n",
    "    deltas = np.array(deltas)\n",
    "    mean_time = deltas.mean()\n",
    "    n = len(deltas)\n",
    "\n",
    "    # Manual exponential fit\n",
    "    rate_manual = 1 / mean_time\n",
    "    ci_half_width = t.ppf(0.975, df=n-1) * sem(deltas)\n",
    "    lower_rate = 1 / (mean_time + ci_half_width)\n",
    "    upper_rate = 1 / (mean_time - ci_half_width)\n",
    "\n",
    "    # Scipy fit with loc fixed to 0\n",
    "    loc, scale = expon.fit(deltas, floc=0)\n",
    "    rate_scipy = 1 / scale\n",
    "\n",
    "    # True rate\n",
    "    rate_true = true_rates[pair]\n",
    "    if time_unit == \"seconds\":\n",
    "        rate_true /= 3600  # convert per hour to per second\n",
    "\n",
    "    # Plot histogram\n",
    "    sns.histplot(deltas, bins=10, stat=\"density\", ax=ax, color=\"skyblue\", label=\"Empirical\")\n",
    "\n",
    "    # X values for plotting\n",
    "    x_vals = np.linspace(0, max(deltas) * 1.2, 200)\n",
    "\n",
    "    # PDF curves\n",
    "    ax.plot(x_vals, expon.pdf(x_vals, scale=1 / rate_manual), color=\"darkblue\",\n",
    "            label=f\"Fitted λ (manual) = {rate_manual:.4f}\")\n",
    "    ax.fill_between(x_vals,\n",
    "                    expon.pdf(x_vals, scale=1 / lower_rate),\n",
    "                    expon.pdf(x_vals, scale=1 / upper_rate),\n",
    "                    color=\"gray\", alpha=0.3, label=\"95% CI band\")\n",
    "    ax.plot(x_vals, expon.pdf(x_vals, scale=1 / rate_scipy), linestyle=\"-.\", color=\"purple\",\n",
    "            label=f\"Fitted λ (scipy) = {rate_scipy:.4f}\")\n",
    "    ax.plot(x_vals, expon.pdf(x_vals, scale=1 / rate_true), linestyle=\"dashed\", color=\"black\",\n",
    "            label=f\"True λ = {rate_true:.4f}\")\n",
    "\n",
    "    # Labels and titles\n",
    "    ax.set_title(f\"{pair[0]} → {pair[1]}\")\n",
    "    ax.set_xlabel(f\"Time ({time_unit})\")\n",
    "    ax.set_ylabel(\"Density\")\n",
    "    ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4fcb5c01f771f4f6",
   "metadata": {},
   "source": [
    "import pm4py\n",
    "\n",
    "pm4py.write_xes(df, \"test.xes\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1000ef66fe0667e6",
   "metadata": {},
   "source": [
    "df"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "dfd2355b9dc4458",
   "metadata": {},
   "source": [
    "final_states = ['End']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "96be41a16a217a8",
   "metadata": {},
   "source": [
    "subset_el = pm4py.convert_to_event_log(df)\n",
    "subset_el = log_parser.add_start_end(subset_el)\n",
    "dfg, start_activities, end_activities = pm4py.discover_dfg(subset_el)\n",
    "dfg[\"end\", \"start\"] = 1"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e1a301b90d3dd19e",
   "metadata": {},
   "source": [
    "pm4py.view_dfg(dfg, start_activities, end_activities)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5b13a70b666c2a8a",
   "metadata": {},
   "source": [
    "subset_el = pm4py.convert_to_dataframe(subset_el)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "316f808aaddc253d",
   "metadata": {},
   "source": [
    "from simulation.timings import Timings"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3954f19e7e9e5397",
   "metadata": {},
   "source": [
    "timings = Timings()\n",
    "resource_input_array = timings.create_resource_input_array_from_log(subset_el)\n",
    "res_timings = timings.get_timings_per_resource(subset_el, resource_input_array)\n",
    "times_dictionary = res_timings"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "33c532ff01d5038c",
   "metadata": {},
   "source": [
    "def extract_times_event_log(log_input):\n",
    "    if type(log_input) == pd.DataFrame:\n",
    "        log = pm4py.convert_to_event_log(deepcopy(log_input))\n",
    "    else:\n",
    "        log = deepcopy(log_input)\n",
    "    times = []\n",
    "    for trace in log:\n",
    "        start = trace[0]['time:timestamp']\n",
    "        end = trace[len(trace)-1] ['time:timestamp']\n",
    "        time = end - start\n",
    "        times.append(time.total_seconds())\n",
    "    return times\n",
    "\n",
    "def extract_times_with_future(log_input):\n",
    "    times_dictionary = {}\n",
    "    if type(log_input) == pd.DataFrame:\n",
    "        log = pm4py.convert_to_event_log(deepcopy(log_input))\n",
    "    else:\n",
    "        log = deepcopy(log_input)\n",
    "    for trace in log:\n",
    "        first = True\n",
    "        for next_event in trace:\n",
    "            if not first and next_event['concept:name'] != 'end' and event['concept:name'] != 'start':\n",
    "                time = next_event['time:timestamp'] - event['time:timestamp']\n",
    "                if not (event['concept:name'], next_event['concept:name']) in times_dictionary.keys():\n",
    "                    times_dictionary[(event['concept:name'], next_event['concept:name'])] = [time.total_seconds()]\n",
    "                else:\n",
    "                    times_dictionary[(event['concept:name'], next_event['concept:name'])].append(time.total_seconds())\n",
    "            event = next_event\n",
    "            first = False\n",
    "    return times_dictionary"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "63a8eb5516bea7f6",
   "metadata": {},
   "source": [
    "extract_times_with_future(subset_el)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b60082b1334bab6d",
   "metadata": {},
   "source": [
    "times_dictionary"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "418f1fe7074ccb93",
   "metadata": {},
   "source": [
    "data_transition_role_frequency = sim_util.get_transition_resource_dict(subset_el)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ea7e0ced8a76c922",
   "metadata": {},
   "source": [
    "data_mean_transition_role_time = {}\n",
    "tuples_to_discard = set()\n",
    "for k,v in data_transition_role_frequency.items():\n",
    "    if k in ['start','end']:\n",
    "        continue\n",
    "    for k2,v2 in v.items():\n",
    "        if k2 in ['start','end']:\n",
    "            continue\n",
    "        all_freq = 0\n",
    "        for k3,v3 in v2.items():\n",
    "            all_freq += v3\n",
    "            if (k,k2,k3) in times_dictionary:\n",
    "                times = times_dictionary[(k,k2,k3)]\n",
    "                times = np.array(times)\n",
    "                times = times/3600\n",
    "                times = times[times != 0]\n",
    "                if len(times) > 1: # only take times that have more than 1 value\n",
    "                    expon_loc, expon_scale = scipy.stats.expon.fit(times)\n",
    "\n",
    "                    # f = Fitter(times, distributions=['expon'])\n",
    "                    # f.fit()\n",
    "                    # best = f.get_best()['expon']\n",
    "                    # expon_loc_fitter, expon_scale_fitter = best['loc'], best['scale']\n",
    "\n",
    "                    if expon_scale>0: # do not take times that cannot be fit into an exponential\n",
    "                        rate = 1/expon_scale\n",
    "                        if k not in data_mean_transition_role_time:\n",
    "                            data_mean_transition_role_time[k] = {}\n",
    "                        if k2 not in data_mean_transition_role_time[k]:\n",
    "                            data_mean_transition_role_time[k][k2] = {}\n",
    "                        if k3 not in data_mean_transition_role_time[k][k2]:\n",
    "                            data_mean_transition_role_time[k][k2][k3] = {\n",
    "                                # 'loc': expon_loc_fitter,\n",
    "                                # 'scale': expon_scale_fitter,\n",
    "                                'loc': expon_loc,\n",
    "                                'scale': expon_scale,\n",
    "                                'lambda': rate\n",
    "                            }\n",
    "                    else:\n",
    "                        print(f\"[No exponential!] {k},{k2},{k3}\")\n",
    "                        tuples_to_discard.add((k,k2,k3))\n",
    "                        print(times)\n",
    "                else:\n",
    "                    print(f\"[No times!] {k},{k2},{k3}\")\n",
    "                    tuples_to_discard.add((k,k2,k3))\n",
    "                    print(times)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e84c6508fe0da157",
   "metadata": {},
   "source": [
    "for (e_from,e_to,role) in tuples_to_discard:\n",
    "    if e_from in data_transition_role_frequency:\n",
    "        if e_to in data_transition_role_frequency[e_from]:\n",
    "            if role in data_transition_role_frequency[e_from][e_to]:\n",
    "                data_transition_role_frequency[e_from][e_to].pop(role)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ce44771e0e586256",
   "metadata": {},
   "source": [
    "for e_from in data_transition_role_frequency.keys():\n",
    "    for e_to in data_transition_role_frequency.keys():\n",
    "        if (e_from == 'start' and e_to == 'start') or (e_from == 'end' and e_to == 'end'):\n",
    "            data_transition_role_frequency[e_from].pop(e_to)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9f660e252723ea3d",
   "metadata": {},
   "source": [
    "def remove_empty_keys(d):\n",
    "    \"\"\"Recursively remove empty keys from a three-level nested dictionary.\"\"\"\n",
    "    if not isinstance(d, dict):\n",
    "        return d  # Return non-dict values as they are\n",
    "\n",
    "    cleaned_dict = {}\n",
    "    for key, value in d.items():\n",
    "        if isinstance(value, dict):\n",
    "            cleaned_value = remove_empty_keys(value)  # Recursively clean sub-dictionaries\n",
    "            if cleaned_value:  # Add only if not empty\n",
    "                cleaned_dict[key] = cleaned_value\n",
    "        elif value not in (None, \"\", [], {}, ()):  # Ignore empty values\n",
    "            cleaned_dict[key] = value\n",
    "\n",
    "    return cleaned_dict\n",
    "\n",
    "data_transition_role_frequency = remove_empty_keys(data_transition_role_frequency)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f9521bb4d2101842",
   "metadata": {},
   "source": [
    "role_resources = sim_util.get_detailed_weighted_role(subset_el)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f89c08e0ea52aee0",
   "metadata": {},
   "source": [
    "role_trials = {k:int(v) for k,v in role_resources.items()}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "279afab90356e582",
   "metadata": {},
   "source": [
    "res = {}\n",
    "out_frequency = {}\n",
    "data_transition_role_prob = {}\n",
    "\n",
    "for k,v in data_transition_role_frequency.items():\n",
    "    if k in ['start','end']:\n",
    "        continue\n",
    "    out_freq = 0\n",
    "    if k not in data_transition_role_prob:\n",
    "        data_transition_role_prob[k] = {}\n",
    "\n",
    "    for k2,v2 in v.items():\n",
    "        if k2 in ['start','end']:\n",
    "            continue\n",
    "        all_freq = 0\n",
    "\n",
    "        if k2 not in data_transition_role_prob[k]:\n",
    "            data_transition_role_prob[k][k2] = {}\n",
    "\n",
    "        if k not in res:\n",
    "            res[k] = {}\n",
    "        if k2 not in res[k]:\n",
    "            for k3,v3 in v2.items():\n",
    "                if k3 not in data_transition_role_prob[k][k2]:\n",
    "                    data_transition_role_prob[k][k2][k3] = v3\n",
    "                all_freq += v3\n",
    "            res[k][k2] = all_freq\n",
    "            out_freq += all_freq\n",
    "        out_frequency[k] = out_freq\n",
    "\n",
    "for k,v in res.items():\n",
    "    for k2,v2 in v.items():\n",
    "        res[k][k2] = res[k][k2]/out_frequency[k]\n",
    "\n",
    "for k,v in data_transition_role_prob.items():\n",
    "    for k2,v2 in v.items():\n",
    "        for k3,v3 in v2.items():\n",
    "            data_transition_role_prob[k][k2][k3] = v3/out_frequency[k]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c0af8ca520b5dc71",
   "metadata": {},
   "source": [
    "view_resource_markov_chain(data_transition_role_prob)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "18584eceec084b36",
   "metadata": {},
   "source": [
    "semi_markov_json = mc_apply(subset_el)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1afadfeeadf40ad",
   "metadata": {},
   "source": [
    "view_markov_chain(semi_markov_json)\n",
    "view_non_resource_markov_chain(res)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cd6b38808cd08069",
   "metadata": {},
   "source": [
    "states = set(subset_el['concept:name'].unique()).difference(set(['start','end']))\n",
    "n = len(states)\n",
    "i = 0\n",
    "correspondence = {s:i for s,i in zip(states,range(len(states)))}\n",
    "#TODO: make sure none of the final states have state = 0 in the prism program\n",
    "non_final_states = list(states.difference(set(final_states)))\n",
    "for s in final_states:\n",
    "    if correspondence[s] == 0:\n",
    "        correspondence[s] = correspondence[non_final_states[0]]\n",
    "        correspondence[non_final_states[0]] = 0\n",
    "correspondence"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d6fce727b45e682d",
   "metadata": {},
   "source": [
    "from simulation.ctmc import create_prism_program_from_log\n",
    "\n",
    "probabilities = create_prism_program_from_log(\n",
    "                            correspondence,\n",
    "                            final_states,\n",
    "                            data_mean_transition_role_time,\n",
    "                            role_resources,\n",
    "                            data_transition_role_frequency,\n",
    "                            role_trials,\n",
    "                            'ctmc.sm')\n",
    "# print(probabilities)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "52337ff3f67c4a78",
   "metadata": {},
   "source": [
    "prism_program = stormpy.parse_prism_program('ctmc.sm',prism_compat=True,simplify=True)\n",
    "model = stormpy.build_model(prism_program)\n",
    "# print(\"Number of states: {}\".format(model.nr_states))\n",
    "# print(\"Number of transitions: {}\".format(model.nr_transitions))\n",
    "# print(\"Labels: {}\".format(model.labeling.get_labels()))\n",
    "labels = \"\"\n",
    "for fs in final_states:\n",
    "    labels += f'\"q_terminal_{fs}\" |'\n",
    "labels = labels[:-2]\n",
    "\n",
    "# formula_str = f'R=? [F {labels}]'\n",
    "formula_str = f'Tmin=? [F {labels}]'\n",
    "# formula_str = f'Rmin=? [C]'\n",
    "\n",
    "properties = stormpy.parse_properties(formula_str, prism_program)\n",
    "result = stormpy.model_checking(model, properties[0])\n",
    "initial_state = model.initial_states[0]\n",
    "result = result.at(initial_state)\n",
    "print(f\"Hours: {result}\")\n",
    "if result<np.inf:\n",
    "    print(f\"Duration: {timedelta(seconds=result)}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "915b3ff996b80089",
   "metadata": {},
   "source": [
    "# Simple choice program"
   ]
  },
  {
   "cell_type": "code",
   "id": "670f27aee18d937f",
   "metadata": {},
   "source": [
    "# prism_program = stormpy.parse_prism_program('ctmc_simple_choice.sm',prism_compat=True,simplify=True)\n",
    "prism_program = stormpy.parse_prism_program('ctmc_basic.sm',prism_compat=True,simplify=True)\n",
    "model = stormpy.build_model(prism_program)\n",
    "# print(\"Number of states: {}\".format(model.nr_states))\n",
    "# print(\"Number of transitions: {}\".format(model.nr_transitions))\n",
    "# print(\"Labels: {}\".format(model.labeling.get_labels()))\n",
    "labels = \"\"\n",
    "for fs in final_states:\n",
    "    labels += f'\"q_terminal_{fs}\" |'\n",
    "labels = labels[:-2]\n",
    "\n",
    "formula_str = f'R=? [F {labels}]'\n",
    "properties = stormpy.parse_properties(formula_str, prism_program)\n",
    "result = stormpy.model_checking(model, properties[0])\n",
    "initial_state = model.initial_states[0]\n",
    "result = result.at(initial_state)\n",
    "print(f\"Hours: {result}\")\n",
    "if result<np.inf:\n",
    "    print(f\"Duration: {timedelta(seconds=result)}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6a60daf69064d45",
   "metadata": {},
   "source": [
    "data_mean_transition_role_time"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f28af840d6ed6b18",
   "metadata": {},
   "source": [
    "pm4py.get_cycle_time(subset_el)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "96c90e8a4eeb981",
   "metadata": {},
   "source": [
    "pm4py.get_all_case_durations(subset_el)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5ef1756524c4dc5a",
   "metadata": {},
   "source": [
    "mean, median, margin_of_error = sim_util.get_pm4py_reference_times(subset_el)\n",
    "print(timedelta(seconds=median))\n",
    "print(timedelta(seconds=mean))\n",
    "print(timedelta(seconds=margin_of_error))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d52e97f4a35afbe2",
   "metadata": {},
   "source": [
    "middle_mean = np.mean(times_dictionary[('Start','Middle','R1')]) + np.mean(times_dictionary[('Middle','End','R1')])\n",
    "start_end_mean = np.mean(times_dictionary[('Start','End','R1')])\n",
    "mean_all = np.mean([middle_mean, start_end_mean])\n",
    "print(timedelta(seconds=mean_all))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "81aeaf1858681fa0",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1d63b9c1-aa8d-42e0-934d-fc3247b50fcd",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bbc7c990-93ee-4eaa-8f31-38a6567619cf",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "973c61e3-138c-4cef-9b5f-c74fda393838",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "36589180-39a1-4a3d-93dd-43ef2c7955cd",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3b1d8608-0acb-432a-9504-3fa28d5e52cb",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "12e936fb-113f-4936-ac44-c61a0ce71c1f",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c6a678a1-a88f-439e-b211-4d1edb3e4ac9",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
